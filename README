ğŸ“Š E-Commerce Data Engineering Pipeline
ğŸš€ Project Overview

This project demonstrates a production-style end-to-end batch ETL data engineering pipeline built to process and analyze large-scale e-commerce sales data.

It simulates a real-world analytics workflow used in retail and marketplace businesses.




The pipeline:

Extracts raw CSV sales data

Cleans and standardizes data using business rules

Performs data quality validation

Loads transformed data into a MySQL data warehouse

Visualizes KPIs using an interactive Streamlit dashboard

The system processes 68,000+ sales records and produces business-level insights including revenue trends, fulfillment performance, and order lifecycle distribution.

ğŸ—ï¸ Architecture
Raw CSV Dataset
        â†“
Extract Layer (Pandas)
        â†“
Transform Layer (Cleaning + Business Logic)
        â†“
Data Quality Checks
        â†“
Load Layer (MySQL Data Warehouse)
        â†“
Analytics Layer (Streamlit Dashboard)

ğŸ“ Project Structure
Ecommerce-Data-Engineering-Pipeline
â”‚
â”œâ”€â”€ Data/
â”‚   â””â”€â”€ README.md          # Instructions to add dataset
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py         # Data extraction logic
â”‚   â”œâ”€â”€ transform.py       # Cleaning + business transformation
â”‚   â”œâ”€â”€ load.py            # MySQL loading (incremental logic)
â”‚   â””â”€â”€ run_pipeline.py    # ETL pipeline runner
â”‚
â”œâ”€â”€ dashboard.py           # Streamlit analytics dashboard
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

ğŸ”§ Key Features
âœ… Modular ETL Design

Separate extract, transform, and load components for maintainability and scalability.

âœ… Data Quality Checks

Duplicate removal

Null handling

Negative revenue filtering

Date validation

âœ… Business Status Normalization

Raw order statuses are standardized into:

Delivered

In Transit

Cancelled

Returned

Pending

This enables clean business-level analytics.

âœ… Incremental Loading

Implements:

ON DUPLICATE KEY UPDATE


Ensures:

No duplicate inserts

Idempotent pipeline runs

Safe reprocessing

âœ… Optimized MySQL Performance

Primary key indexing on order_id

Aggregation-ready schema

âœ… Interactive Dashboard KPIs

ğŸ’° Total Revenue

ğŸ“¦ Total Orders

ğŸ¢ B2B Orders

âŒ Cancellation Rate

ğŸ›’ Average Order Value (AOV)

ğŸšš Fulfillment Revenue Split

ğŸ“ Revenue by State

ğŸ“ˆ Monthly Revenue Trend

ğŸ“¦ Order Lifecycle Distribution

ğŸ—„ Database Schema
Table: sales_data
Column	Description
order_id	Primary Key
order_date	Order date
amount	Revenue per record
business_status	Normalized order lifecycle
ship_state	Shipping state
fulfilment	Amazon / Merchant
b2b	B2B flag
ğŸ“‚ Dataset

The dataset is not included in this repository due to size constraints.

You can download it from Kaggle:

ğŸ‘‰ https://www.kaggle.com/datasets/thedevastator/unlock-profits-with-e-commerce-sales-data

Setup Instructions

Download the dataset from Kaggle.

Rename the file to:

raw_sales.csv


Place it inside the Data/ folder:

Data/raw_sales.csv

â–¶ï¸ How to Run the Project
1ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

2ï¸âƒ£ Set Environment Variable (Windows)
set DB_PASSWORD=your_mysql_password


(Mac/Linux)

export DB_PASSWORD=your_mysql_password

3ï¸âƒ£ Run ETL Pipeline
cd etl
python run_pipeline.py

4ï¸âƒ£ Start Dashboard
streamlit run dashboard.py


Then open:

http://localhost:8501

ğŸ“Š Business Insights Generated

From the dataset:

~14% cancellation rate

~1.7% return rate

Strong revenue concentration across specific states

Significant revenue split between Amazon and Merchant fulfillment

Clear order lifecycle segmentation (In Transit, Delivered, Returned, etc.)

ğŸ›  Tech Stack

Python

Pandas

MySQL

SQLAlchemy

Streamlit

Logging

Modular ETL Architecture

ğŸ“ˆ Future Improvements

Add Apache Airflow scheduling

Dockerize the pipeline

Replace Pandas with PySpark for large-scale processing

Deploy dashboard to cloud (AWS/GCP/Azure)

Add CI/CD workflow

ğŸ‘¨â€ğŸ’» Author

Yashas G M
